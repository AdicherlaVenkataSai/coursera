{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6. Validation and Test Sets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPfqE5+hoFovayzczz6r+P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdicherlaVenkataSai/GooglecrashML/blob/master/6.%20Validation_and_Test_Sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FB-cml4yo21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1dJULLny-0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEcHldbFzUoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "test = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjgHq6AKzZkJ",
        "colab_type": "code",
        "outputId": "e2d61bf4-1b1d-4292-f60e-58b9c1f37b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  ...  median_income  median_house_value\n",
              "0    -114.31     34.19  ...         1.4936             66900.0\n",
              "1    -114.47     34.40  ...         1.8200             80100.0\n",
              "2    -114.56     33.69  ...         1.6509             85700.0\n",
              "3    -114.57     33.64  ...         3.1917             73400.0\n",
              "4    -114.57     33.57  ...         1.9250             65500.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3O4KwwvzdpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Scale the training set's label.\n",
        "train[\"median_house_value\"] /= 1000.0\n",
        "\n",
        "# Scale the test set's label\n",
        "test[\"median_house_value\"] /= 1000.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbtbWoygzuK5",
        "colab_type": "code",
        "outputId": "3c34a667-f6f2-4248-d865-0d9deca6e836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#title Define the functions that build and train a model\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Compile the model topography into code that TensorFlow can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error. \n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model               \n",
        "\n",
        "\n",
        "def train_model(model, df, feature, label, my_epochs, \n",
        "                my_batch_size=None, my_validation_split=0.1):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  history = model.fit(x=df[feature],\n",
        "                      y=df[label],\n",
        "                      batch_size=my_batch_size,\n",
        "                      epochs=my_epochs,\n",
        "                      validation_split=my_validation_split)\n",
        "\n",
        "  # Gather the model's trained weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the \n",
        "  # rest of history.\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  # Isolate the root mean squared error for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history   \n",
        "\n",
        "print(\"Defined the build_model and train_model functions.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the build_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RdrmJ2s22a5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bfb001c-64b7-4184-d43b-4d92a775db0d"
      },
      "source": [
        "#title Define the plotting function\n",
        "\n",
        "def plot_the_loss_curve(epochs, mae_training, mae_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mae_training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], mae_validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  \n",
        "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
        "  # is often substantially greater than the loss for other epochs.\n",
        "  merged_mae_lists = mae_training[1:] + mae_validation[1:]\n",
        "  highest_loss = max(merged_mae_lists)\n",
        "  lowest_loss = min(merged_mae_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "   \n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92dZrd9O302k",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Experiment with the validation split\n",
        "\n",
        "In the following code cell, you'll see a variable named `validation_split`, which we've initialized at 0.2.  The `validation_split` variable specifies the proportion of the original training set that will serve as the validation set. The original training set contains 17,000 examples. Therefore, a `validation_split` of 0.2 means that:\n",
        "\n",
        "* 17,000 * 0.2 ~= 3,400 examples will become the validation set.\n",
        "* 17,000 * 0.8 ~= 13,600 examples will become the new training set.\n",
        "\n",
        "The following code builds a model, trains it on the training set, and evaluates the built model on both:\n",
        "\n",
        "* The training set.\n",
        "* And the validation set.\n",
        "\n",
        "If the data in the training set is similar to the data in the validation set, then the two loss curves and the final loss values should be almost identical. However, the loss curves and final loss values are **not** almost identical. Hmm, that's odd.  \n",
        "\n",
        "Experiment with two or three different values of `validation_split`.  Do different values of `validation_split` fix the problem? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6qinwWczfrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29d576ad-5de0-44be-e033-f4dc8b402902"
      },
      "source": [
        "#hyperparameters\n",
        "learning_rate = 0.08\n",
        "epochs = 30\n",
        "batch_size  = 100\n",
        "\n",
        "validation_splt = 0.2\n",
        "\n",
        "feature = \"medain_income\"\n",
        "label = \"medain_house_value\"\n",
        "\n",
        "\n",
        "model = None# The following variables are the hyperparameters.\n",
        "learning_rate = 0.08\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into a reduced training set and a\n",
        "# validation set. \n",
        "validation_split=0.2\n",
        "\n",
        "# Identify the feature and the label.\n",
        "my_feature=\"median_income\"  # the median income on a specific city block.\n",
        "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based \n",
        "# solely on the neighborhood's median income.  \n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "my_model = None\n",
        "\n",
        "# Invoke the functions to build and train the model.\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, train, my_feature, \n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(model, train, feature, label,\n",
        "                                    epochs, batch_size, validation_splt)\n",
        "\n",
        "loss_curve_plot(epochs, history['root_mean_squared_error'], \n",
        "                history['val_root_mean_squared_error'])\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 41259.4570 - root_mean_squared_error: 203.1242 - val_loss: 50026.6602 - val_root_mean_squared_error: 223.6664\n",
            "Epoch 2/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 23998.4844 - root_mean_squared_error: 154.9144 - val_loss: 29503.7734 - val_root_mean_squared_error: 171.7666\n",
            "Epoch 3/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 12686.0752 - root_mean_squared_error: 112.6325 - val_loss: 16016.6855 - val_root_mean_squared_error: 126.5571\n",
            "Epoch 4/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7446.2422 - root_mean_squared_error: 86.2916 - val_loss: 9809.9355 - val_root_mean_squared_error: 99.0451\n",
            "Epoch 5/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6516.9766 - root_mean_squared_error: 80.7278 - val_loss: 9352.9609 - val_root_mean_squared_error: 96.7107\n",
            "Epoch 6/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6514.0889 - root_mean_squared_error: 80.7099 - val_loss: 9234.9717 - val_root_mean_squared_error: 96.0988\n",
            "Epoch 7/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6512.6587 - root_mean_squared_error: 80.7010 - val_loss: 9409.9443 - val_root_mean_squared_error: 97.0049\n",
            "Epoch 8/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6514.4429 - root_mean_squared_error: 80.7121 - val_loss: 9323.8340 - val_root_mean_squared_error: 96.5600\n",
            "Epoch 9/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6512.6245 - root_mean_squared_error: 80.7008 - val_loss: 9279.0771 - val_root_mean_squared_error: 96.3280\n",
            "Epoch 10/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6513.6157 - root_mean_squared_error: 80.7070 - val_loss: 9201.9297 - val_root_mean_squared_error: 95.9267\n",
            "Epoch 11/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6514.4580 - root_mean_squared_error: 80.7122 - val_loss: 9223.6504 - val_root_mean_squared_error: 96.0398\n",
            "Epoch 12/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6513.7183 - root_mean_squared_error: 80.7076 - val_loss: 9356.4492 - val_root_mean_squared_error: 96.7287\n",
            "Epoch 13/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6513.8730 - root_mean_squared_error: 80.7086 - val_loss: 9209.8096 - val_root_mean_squared_error: 95.9678\n",
            "Epoch 14/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6512.3218 - root_mean_squared_error: 80.6990 - val_loss: 9120.2168 - val_root_mean_squared_error: 95.4998\n",
            "Epoch 15/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6514.8418 - root_mean_squared_error: 80.7146 - val_loss: 9241.7656 - val_root_mean_squared_error: 96.1341\n",
            "Epoch 16/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6512.9082 - root_mean_squared_error: 80.7026 - val_loss: 9418.6963 - val_root_mean_squared_error: 97.0500\n",
            "Epoch 17/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6514.3955 - root_mean_squared_error: 80.7118 - val_loss: 9326.3975 - val_root_mean_squared_error: 96.5733\n",
            "Epoch 18/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6512.5249 - root_mean_squared_error: 80.7002 - val_loss: 9206.8428 - val_root_mean_squared_error: 95.9523\n",
            "Epoch 19/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6513.8599 - root_mean_squared_error: 80.7085 - val_loss: 9224.9043 - val_root_mean_squared_error: 96.0464\n",
            "Epoch 20/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6509.2910 - root_mean_squared_error: 80.6802 - val_loss: 9462.5000 - val_root_mean_squared_error: 97.2754\n",
            "Epoch 21/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6515.1929 - root_mean_squared_error: 80.7167 - val_loss: 9350.1396 - val_root_mean_squared_error: 96.6961\n",
            "Epoch 22/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6513.8701 - root_mean_squared_error: 80.7085 - val_loss: 9212.4180 - val_root_mean_squared_error: 95.9813\n",
            "Epoch 23/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6513.5898 - root_mean_squared_error: 80.7068 - val_loss: 9284.5762 - val_root_mean_squared_error: 96.3565\n",
            "Epoch 24/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6512.9912 - root_mean_squared_error: 80.7031 - val_loss: 9107.5410 - val_root_mean_squared_error: 95.4334\n",
            "Epoch 25/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6513.6382 - root_mean_squared_error: 80.7071 - val_loss: 9303.0332 - val_root_mean_squared_error: 96.4522\n",
            "Epoch 26/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6514.0171 - root_mean_squared_error: 80.7095 - val_loss: 9302.9834 - val_root_mean_squared_error: 96.4520\n",
            "Epoch 27/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6512.5410 - root_mean_squared_error: 80.7003 - val_loss: 9336.1777 - val_root_mean_squared_error: 96.6239\n",
            "Epoch 28/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6513.6455 - root_mean_squared_error: 80.7072 - val_loss: 9353.9834 - val_root_mean_squared_error: 96.7160\n",
            "Epoch 29/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6511.8589 - root_mean_squared_error: 80.6961 - val_loss: 9128.5117 - val_root_mean_squared_error: 95.5432\n",
            "Epoch 30/30\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 6512.7954 - root_mean_squared_error: 80.7019 - val_loss: 9321.1494 - val_root_mean_squared_error: 96.5461\n",
            "91.08645629882812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'medain_income'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4dabefdd87ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m epochs, rmse, history = train_model(model, train, feature, label,\n\u001b[0;32m---> 41\u001b[0;31m                                     epochs, batch_size, validation_splt)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m loss_curve_plot(epochs, history['root_mean_squared_error'], \n",
            "\u001b[0;32m<ipython-input-13-02c8f35d61b2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, df, feature, label, my_epochs, my_batch_size, my_validation_split)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;34m\"\"\"Feed a dataset into the model in order to train it.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   history = model.fit(x=df[feature],\n\u001b[0m\u001b[1;32m     24\u001b[0m                       \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'medain_income'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHgW9H8d4TWg",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: Determine **why** the loss curves differ\n",
        "\n",
        "No matter how you split the training set and the validation set, the loss curves differ significantly. Evidently, the data in the training set isn't similar enough to the data in the validation set. Counterintuitive? Yes, but this problem is actually pretty common in machine learning. \n",
        "\n",
        "Your task is to determine **why** the loss curves aren't highly similar. As with most issues in machine learning, the problem is rooted in the data itself. To solve this mystery of why the training set and validation set aren't almost identical, write a line or two of [pandas code](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=validation-colab&utm_medium=colab&utm_campaign=colab-external&utm_content=pandas_tf2-colab&hl=en) in the following code cell.  Here are a couple of hints:\n",
        "\n",
        "  * The previous code cell split the original training set into:\n",
        "    * a reduced training set (the original training set - the validation set)\n",
        "    * the validation set \n",
        "  * By default, the pandas [`head`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method outputs the *first* 5 rows of the DataFrame. To see more of the training set, specify the `n` argument to `head` and assign a large positive integer to `n`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EllL0qms4T_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "1d76913c-9ca8-4014-c53a-b5ea86cf1cb0"
      },
      "source": [
        "#title Double-click for a possible solution to Task 2.\n",
        "\n",
        "# Examine examples 0 through 4 and examples 25 through 29\n",
        "# of the training set\n",
        "train.head(n=1000)\n",
        "\n",
        "# The original training set is sorted by longitude. \n",
        "# Apparently, longitude influences the relationship of\n",
        "# total_rooms to median_house_value."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-117.09</td>\n",
              "      <td>32.55</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6533.0</td>\n",
              "      <td>1217.0</td>\n",
              "      <td>4797.0</td>\n",
              "      <td>1177.0</td>\n",
              "      <td>3.9583</td>\n",
              "      <td>144.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-117.10</td>\n",
              "      <td>34.57</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5110.0</td>\n",
              "      <td>1044.0</td>\n",
              "      <td>1938.0</td>\n",
              "      <td>724.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>112.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>-117.10</td>\n",
              "      <td>34.21</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4397.0</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>445.0</td>\n",
              "      <td>4.5268</td>\n",
              "      <td>108.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-117.10</td>\n",
              "      <td>34.03</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4144.0</td>\n",
              "      <td>826.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>772.0</td>\n",
              "      <td>2.5172</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-117.10</td>\n",
              "      <td>33.56</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1868.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>4.3833</td>\n",
              "      <td>307.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     longitude  latitude  ...  median_income  median_house_value\n",
              "0      -114.31     34.19  ...         1.4936                66.9\n",
              "1      -114.47     34.40  ...         1.8200                80.1\n",
              "2      -114.56     33.69  ...         1.6509                85.7\n",
              "3      -114.57     33.64  ...         3.1917                73.4\n",
              "4      -114.57     33.57  ...         1.9250                65.5\n",
              "..         ...       ...  ...            ...                 ...\n",
              "995    -117.09     32.55  ...         3.9583               144.4\n",
              "996    -117.10     34.57  ...         3.1917               112.8\n",
              "997    -117.10     34.21  ...         4.5268               108.4\n",
              "998    -117.10     34.03  ...         2.5172                96.0\n",
              "999    -117.10     33.56  ...         4.3833               307.6\n",
              "\n",
              "[1000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHiLikPk4gos",
        "colab_type": "text"
      },
      "source": [
        "## Task 3. Fix the problem\n",
        "\n",
        "To fix the problem, shuffle the examples in the training set before splitting the examples into a training set and validation set. To do so, take the following steps:\n",
        "\n",
        "1. Shuffle the data in the training set by adding the following line anywhere before you call `train_model` (in the code cell associated with Task 1):\n",
        "\n",
        "```\n",
        "  shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
        "```                                    \n",
        "\n",
        "2. Pass `shuffled_train_df` (instead of `train_df`) as the second argument to `train_model` (in the code call associated with Task 1) so that the call becomes as follows:\n",
        "\n",
        "```\n",
        "  epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
        "                                      my_label, epochs, batch_size, \n",
        "                                      validation_split)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSCRpzxh4YBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eea9be8c-f889-41d5-a43e-095c3757e37f"
      },
      "source": [
        "\n",
        "#hyperparameter\n",
        "\n",
        "learning_rate = 0.08\n",
        "epochs = 70\n",
        "batch_size = 100\n",
        "\n",
        "validation_split = 0.2\n",
        "\n",
        "# Identify the feature and the label.\n",
        "my_feature=\"median_income\"  # the median income on a specific city block.\n",
        "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based \n",
        "# solely on the neighborhood's median income.  \n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "my_model = None\n",
        "\n",
        "#shuffle the examples\n",
        "shuffled_train = train.reindex(np.random.permutation(train.index))\n",
        "\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, shuffled_train, my_feature, \n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 45249.3711 - root_mean_squared_error: 212.7190 - val_loss: 34246.5039 - val_root_mean_squared_error: 185.0581\n",
            "Epoch 2/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 26712.6367 - root_mean_squared_error: 163.4400 - val_loss: 18811.8359 - val_root_mean_squared_error: 137.1562\n",
            "Epoch 3/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 14489.4531 - root_mean_squared_error: 120.3721 - val_loss: 9814.1553 - val_root_mean_squared_error: 99.0664\n",
            "Epoch 4/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 8357.6699 - root_mean_squared_error: 91.4203 - val_loss: 6824.4243 - val_root_mean_squared_error: 82.6101\n",
            "Epoch 5/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7082.7251 - root_mean_squared_error: 84.1589 - val_loss: 6800.7896 - val_root_mean_squared_error: 82.4669\n",
            "Epoch 6/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.3926 - root_mean_squared_error: 84.0856 - val_loss: 6786.1470 - val_root_mean_squared_error: 82.3781\n",
            "Epoch 7/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.9888 - root_mean_squared_error: 84.0892 - val_loss: 6793.6846 - val_root_mean_squared_error: 82.4238\n",
            "Epoch 8/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 7070.4189 - root_mean_squared_error: 84.0858 - val_loss: 6795.1885 - val_root_mean_squared_error: 82.4329\n",
            "Epoch 9/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.9453 - root_mean_squared_error: 84.0830 - val_loss: 6802.8271 - val_root_mean_squared_error: 82.4793\n",
            "Epoch 10/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.8555 - root_mean_squared_error: 84.0824 - val_loss: 6787.2700 - val_root_mean_squared_error: 82.3849\n",
            "Epoch 11/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.9829 - root_mean_squared_error: 84.0891 - val_loss: 6799.9404 - val_root_mean_squared_error: 82.4618\n",
            "Epoch 12/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7071.1226 - root_mean_squared_error: 84.0900 - val_loss: 6794.4834 - val_root_mean_squared_error: 82.4287\n",
            "Epoch 13/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.1025 - root_mean_squared_error: 84.0839 - val_loss: 6798.3960 - val_root_mean_squared_error: 82.4524\n",
            "Epoch 14/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.9487 - root_mean_squared_error: 84.0830 - val_loss: 6787.9175 - val_root_mean_squared_error: 82.3888\n",
            "Epoch 15/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.4990 - root_mean_squared_error: 84.0863 - val_loss: 6789.1577 - val_root_mean_squared_error: 82.3963\n",
            "Epoch 16/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.1001 - root_mean_squared_error: 84.0839 - val_loss: 6788.0981 - val_root_mean_squared_error: 82.3899\n",
            "Epoch 17/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7071.4746 - root_mean_squared_error: 84.0921 - val_loss: 6791.2681 - val_root_mean_squared_error: 82.4091\n",
            "Epoch 18/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.3789 - root_mean_squared_error: 84.0855 - val_loss: 6796.6953 - val_root_mean_squared_error: 82.4421\n",
            "Epoch 19/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.7827 - root_mean_squared_error: 84.0879 - val_loss: 6794.5410 - val_root_mean_squared_error: 82.4290\n",
            "Epoch 20/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.7324 - root_mean_squared_error: 84.0817 - val_loss: 6803.3853 - val_root_mean_squared_error: 82.4826\n",
            "Epoch 21/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.2788 - root_mean_squared_error: 84.0850 - val_loss: 6801.3848 - val_root_mean_squared_error: 82.4705\n",
            "Epoch 22/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.6372 - root_mean_squared_error: 84.0811 - val_loss: 6808.5024 - val_root_mean_squared_error: 82.5136\n",
            "Epoch 23/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.5708 - root_mean_squared_error: 84.0807 - val_loss: 6789.6274 - val_root_mean_squared_error: 82.3992\n",
            "Epoch 24/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.8647 - root_mean_squared_error: 84.0825 - val_loss: 6800.4258 - val_root_mean_squared_error: 82.4647\n",
            "Epoch 25/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.9609 - root_mean_squared_error: 84.0831 - val_loss: 6795.1982 - val_root_mean_squared_error: 82.4330\n",
            "Epoch 26/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.5635 - root_mean_squared_error: 84.0807 - val_loss: 6803.2939 - val_root_mean_squared_error: 82.4821\n",
            "Epoch 27/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7068.9116 - root_mean_squared_error: 84.0768 - val_loss: 6785.2500 - val_root_mean_squared_error: 82.3726\n",
            "Epoch 28/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.9395 - root_mean_squared_error: 84.0889 - val_loss: 6789.5283 - val_root_mean_squared_error: 82.3986\n",
            "Epoch 29/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.8833 - root_mean_squared_error: 84.0826 - val_loss: 6798.2070 - val_root_mean_squared_error: 82.4512\n",
            "Epoch 30/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.6943 - root_mean_squared_error: 84.0874 - val_loss: 6795.5381 - val_root_mean_squared_error: 82.4351\n",
            "Epoch 31/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7066.8398 - root_mean_squared_error: 84.0645 - val_loss: 6817.8447 - val_root_mean_squared_error: 82.5702\n",
            "Epoch 32/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7071.1187 - root_mean_squared_error: 84.0899 - val_loss: 6801.7705 - val_root_mean_squared_error: 82.4728\n",
            "Epoch 33/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.7725 - root_mean_squared_error: 84.0819 - val_loss: 6784.6611 - val_root_mean_squared_error: 82.3691\n",
            "Epoch 34/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.0337 - root_mean_squared_error: 84.0835 - val_loss: 6801.7266 - val_root_mean_squared_error: 82.4726\n",
            "Epoch 35/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7068.6289 - root_mean_squared_error: 84.0751 - val_loss: 6784.9795 - val_root_mean_squared_error: 82.3710\n",
            "Epoch 36/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.8130 - root_mean_squared_error: 84.0822 - val_loss: 6808.8906 - val_root_mean_squared_error: 82.5160\n",
            "Epoch 37/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7071.0957 - root_mean_squared_error: 84.0898 - val_loss: 6799.9604 - val_root_mean_squared_error: 82.4619\n",
            "Epoch 38/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.3628 - root_mean_squared_error: 84.0854 - val_loss: 6792.5024 - val_root_mean_squared_error: 82.4166\n",
            "Epoch 39/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.3110 - root_mean_squared_error: 84.0851 - val_loss: 6795.0425 - val_root_mean_squared_error: 82.4320\n",
            "Epoch 40/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.5396 - root_mean_squared_error: 84.0865 - val_loss: 6786.7144 - val_root_mean_squared_error: 82.3815\n",
            "Epoch 41/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.9189 - root_mean_squared_error: 84.0828 - val_loss: 6786.3672 - val_root_mean_squared_error: 82.3794\n",
            "Epoch 42/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.0967 - root_mean_squared_error: 84.0839 - val_loss: 6785.6851 - val_root_mean_squared_error: 82.3753\n",
            "Epoch 43/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.2329 - root_mean_squared_error: 84.0847 - val_loss: 6802.6875 - val_root_mean_squared_error: 82.4784\n",
            "Epoch 44/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.3887 - root_mean_squared_error: 84.0856 - val_loss: 6801.8228 - val_root_mean_squared_error: 82.4732\n",
            "Epoch 45/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.5894 - root_mean_squared_error: 84.0868 - val_loss: 6789.5938 - val_root_mean_squared_error: 82.3990\n",
            "Epoch 46/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 7070.3242 - root_mean_squared_error: 84.0852 - val_loss: 6797.2920 - val_root_mean_squared_error: 82.4457\n",
            "Epoch 47/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7068.8345 - root_mean_squared_error: 84.0764 - val_loss: 6795.3447 - val_root_mean_squared_error: 82.4339\n",
            "Epoch 48/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.4165 - root_mean_squared_error: 84.0798 - val_loss: 6796.0801 - val_root_mean_squared_error: 82.4383\n",
            "Epoch 49/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.6362 - root_mean_squared_error: 84.0811 - val_loss: 6793.1987 - val_root_mean_squared_error: 82.4209\n",
            "Epoch 50/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7071.0942 - root_mean_squared_error: 84.0898 - val_loss: 6793.4458 - val_root_mean_squared_error: 82.4224\n",
            "Epoch 51/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 7068.5664 - root_mean_squared_error: 84.0748 - val_loss: 6812.9287 - val_root_mean_squared_error: 82.5405\n",
            "Epoch 52/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.2153 - root_mean_squared_error: 84.0846 - val_loss: 6784.6758 - val_root_mean_squared_error: 82.3691\n",
            "Epoch 53/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.9131 - root_mean_squared_error: 84.0887 - val_loss: 6791.6636 - val_root_mean_squared_error: 82.4116\n",
            "Epoch 54/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.6245 - root_mean_squared_error: 84.0811 - val_loss: 6786.0576 - val_root_mean_squared_error: 82.3775\n",
            "Epoch 55/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.2563 - root_mean_squared_error: 84.0848 - val_loss: 6793.6196 - val_root_mean_squared_error: 82.4234\n",
            "Epoch 56/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.2080 - root_mean_squared_error: 84.0786 - val_loss: 6808.1987 - val_root_mean_squared_error: 82.5118\n",
            "Epoch 57/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.4077 - root_mean_squared_error: 84.0857 - val_loss: 6789.8599 - val_root_mean_squared_error: 82.4006\n",
            "Epoch 58/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.2720 - root_mean_squared_error: 84.0790 - val_loss: 6795.9731 - val_root_mean_squared_error: 82.4377\n",
            "Epoch 59/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.0898 - root_mean_squared_error: 84.0779 - val_loss: 6805.7339 - val_root_mean_squared_error: 82.4969\n",
            "Epoch 60/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7069.6953 - root_mean_squared_error: 84.0815 - val_loss: 6800.1094 - val_root_mean_squared_error: 82.4628\n",
            "Epoch 61/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.3325 - root_mean_squared_error: 84.0853 - val_loss: 6792.8169 - val_root_mean_squared_error: 82.4185\n",
            "Epoch 62/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.3359 - root_mean_squared_error: 84.0853 - val_loss: 6799.5605 - val_root_mean_squared_error: 82.4594\n",
            "Epoch 63/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7067.7119 - root_mean_squared_error: 84.0697 - val_loss: 6815.1982 - val_root_mean_squared_error: 82.5542\n",
            "Epoch 64/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7068.2246 - root_mean_squared_error: 84.0727 - val_loss: 6795.9487 - val_root_mean_squared_error: 82.4375\n",
            "Epoch 65/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.6777 - root_mean_squared_error: 84.0873 - val_loss: 6792.9878 - val_root_mean_squared_error: 82.4196\n",
            "Epoch 66/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.6455 - root_mean_squared_error: 84.0871 - val_loss: 6788.7280 - val_root_mean_squared_error: 82.3937\n",
            "Epoch 67/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.1152 - root_mean_squared_error: 84.0840 - val_loss: 6794.4351 - val_root_mean_squared_error: 82.4284\n",
            "Epoch 68/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.2124 - root_mean_squared_error: 84.0846 - val_loss: 6788.6533 - val_root_mean_squared_error: 82.3933\n",
            "Epoch 69/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.6812 - root_mean_squared_error: 84.0873 - val_loss: 6796.2729 - val_root_mean_squared_error: 82.4395\n",
            "Epoch 70/70\n",
            "136/136 [==============================] - 0s 1ms/step - loss: 7070.6206 - root_mean_squared_error: 84.0870 - val_loss: 6791.1235 - val_root_mean_squared_error: 82.4083\n",
            "81.0709457397461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwmsp-5l5wZo",
        "colab_type": "text"
      },
      "source": [
        "Experiment with `validation_split` to answer the following questions:\n",
        "\n",
        "* With the training set shuffled, is the final loss for the training set closer to the final loss for the validation set?  \n",
        "* At what range of values of `validation_split` do the final loss values for the training set and validation set diverge meaningfully?  Why?\n",
        "\n",
        "\n",
        "sol :\n",
        "```\n",
        "Yes, after shuffling the original training set, the final loss for the training set and the validation set become much closer\n",
        "\n",
        "If the val split < 0.15, the final loss values or the training set and val set diverge meaningfully. Apparently the val set no longer contains enough examples\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEXR1ATI6mcX",
        "colab_type": "text"
      },
      "source": [
        "## Task 4: Use the Test Dataset to Evaluate Your Model's Performance\n",
        "\n",
        "The test set usually acts as the ultimate judge of a model's quality. The test set can serve as an impartial judge because its examples haven't been used in training the model. Run the following code cell to evaluate the model with the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDTBDtdR5xHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1a371bff-9dae-457d-a99b-0f2996473f5b"
      },
      "source": [
        "x_test = test[my_feature]\n",
        "y_test = test[my_label]\n",
        "\n",
        "results = my_model.evaluate(x_test, y_test, batch_size=batch_size)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 0s 1ms/step - loss: 7009.9893 - root_mean_squared_error: 83.7257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SKijddF7E3A",
        "colab_type": "text"
      },
      "source": [
        "Compare the root mean squared error of the model when evaluated on each of the three datasets:\n",
        "\n",
        "* training set: look for `root_mean_squared_error` in the final training epoch.\n",
        "* validation set: look for `val_root_mean_squared_error` in the final training epoch.\n",
        "* test set: run the preceding code cell and examine the `root_mean_squred_error`.\n",
        "\n",
        "Ideally, the root mean squared error of all three sets should be similar. Are they?\n",
        "\n",
        "sol:\n",
        "```\n",
        "In this experiment the rmse values were similar enough\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nOmLHio7RH5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT8Tu7_h60yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}